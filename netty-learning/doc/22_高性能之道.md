即为什么说Netty是高性能的网络通信框架，主要有以下几点：

---
### 异步非阻塞通信
* `Netty`的`I/O`线程`NioEventLoop`由于聚合了多路复用器`Selector`，可以同时并发处理成百上千个客户端`SocketChannel`。由于读写操作都是非阻塞的，这就可以充分提升`I/O`线程的运行效率，避免由频繁的`I/O`阻塞导致的线程挂起。
* `Netty`采用了异步通信模式，一个`I/O`线程可以并发处理`N`个客户端连接和读写操作。

### 高效的Reactor线程模型
* `Reactor`单线程模型
<br>所有的`I/O`操作都在同一个`NIO`线程上完成。<br>对于一些小容量应用场景，可以使用单线程模型。但是对于高负载、大并发的应用却不合适，主要原因如下：
  * 一个`NIO`线程同时处理成百上千的链路，性能上无法支撑，即便NIO线程的CPU负荷达到100%，也无法满足海量消息的编码、解码、读取和发送；
  * 当`NIO`线程负载过重之后，处理速度将变慢，这会导致大量客户端连接超时，超时之后往往会进行重发，这更加重了NIO线程的负载，最终会导致大量消息积压和处理超时，NIO线程会成为系统的性能瓶颈；
  * 可靠性问题：一旦`NIO`线程意外跑飞，或者进入死循环，会导致整个系统通信模块不可用，不能接收和处理外部消息，造成节点故障。

* `Reactor`多线程模型
<br>有一组NIO线程处理I/O操作。
  * 有一个专门的`NIO`线程(`Acceptor`线程)用于监听服务端，接收客户端的`TCP`连接请求。
  * 网络`I/O`操作（读、写等）由一个`NIO`线程池负责，线程池可以采用标准的`JDK`线程池实现，它包含一个任务队列和`N`个可用的线程，由这些`NIO`线程负责消息的读取、解码、编码和发送；
  * 1个`NIO`线程可以同时处理`N`条链路，但是1个链路只对应1个`NIO`线程，防止发生并发操作问题。
<br><br>在绝大多数场景下，`Reactor`多线程模型都可以满足性能需求；但是，在极特殊应用场景中，一个`NIO`线程负责监听和处理所有的客户端连接可能会存在性能问题。例如百万客户端并发连接，或者服务端需要对客户端的握手消息进行安全认证，认证本身非常损耗性能。在这类场景下，单独一个`Acceptor`线程可能会存在性能不足问题，为了解决性能问题，产生了第三种`Reactor`线程模型-主从`Reactor`多线程模型。

* 主从`Reactor`多线程模型
<br>与Reactor多线程模型不同的是，服务端用于接收客户端连接的不再是1个单独的`NIO`线程，而是一个独立的`NIO`线程池。`Acceptor`接收到客户端`TCP`连接请求处理完成后，将新创建的`SocketChannel`注册到`I/O`线程池。`Acceptor`线程池只用于客户端的登陆、握手和安全认证，一旦链路建立成功，就将链路注册到后端线程池的`I/O`线程上，由`I/O`线程负责后续的`I/O`操作。

Netty可以通过设置不同的参数（不同的的`EventLoopGroup`实例）实现上述三中Reactor线程模型。

### 无锁化的串行设计

在大多数场景下，并行多线程处理可以提升系统的并发性能。但是，如果对于共享资源的并发访问处理不当，会带来严重的锁竞争，这最终会导致性能的下降。为了尽可能的避免锁竞争带来的性能损耗，可以通过串行化设计，即消息的处理尽可能在同一个线程内完成，期间不进行线程切换，这样就避免了多线程竞争和同步锁。

为了尽可能提升性能，`Netty`采用了串行无锁化设计，在`IO`线程内部进行串行操作，避免多线程竞争导致的性能下降。表面上看，串行化设计似乎`CPU`利用率不高，并发程度不够。但是，通过调整`NIO`线程池的线程参数，可以同时启动多个串行化的线程并行运行，这种局部无锁化的串行线程设计相比一个队列-多个工作线程模型性能更优。

`Netty`的串行化设计工作原理图如下：

![Netty串行化工作原理图](https://github.com/maxwellyue/network-programming/blob/master/netty-learning/doc/images/Netty%E4%B8%B2%E8%A1%8C%E5%8C%96%E8%AE%BE%E8%AE%A1%E5%B7%A5%E4%BD%9C%E5%8E%9F%E7%90%86.png?raw=true)

`Netty`的`NioEventLoop`读取到消息之后，直接调用`ChannelPipeline`的`fireChannelRead(Object msg)`，只要用户不主动切换线程，一直会由`NioEventLoop`调用到用户的`Handler`，期间不进行线程切换，这种串行化处理方式避免了多线程操作导致的锁的竞争，从性能角度看是最优的。

### 高效的并发编程

Netty的高效并发编程主要体现在如下几点：

* volatile的大量、正确使用;

* CAS和原子类的广泛使用；

* 线程安全容器的使用；

* 通过读写锁提升并发性能。

### 高性能的序列化框架
影响序列化性能的关键因素总结如下：①序列化后的码流大小（网络带宽的占用）；②序列化&反序列化的性能（CPU资源占用）；③是否支持跨语言（异构系统的对接和开发语言切换）。

`Netty`默认提供了对`Google Protobuf`的支持。通过扩展`Netty`的编解码接口，用户可以实现其它的高性能序列化框架，例如`Thrift`的压缩二进制编解码框架。

### 零拷贝

`Netty`的零拷贝主要体现在如下三个方面：

* `ByteBuffer`采用`DIRECT BUFFERS`，使用堆外直接内存进行`Socket`读写，不需要进行字节缓冲区的二次拷贝。如果使用传统的堆内存进行`Socket`读写，`JVM`会将堆内存`Buffer`拷贝一份到直接内存中，然后才写入`Socket`中。相比于堆外直接内存，消息在发送过程中多了一次缓冲区的内存拷贝。

* `Netty`提供了组合`Buffer`对象，可以聚合多个`ByteBuffer`对象，用户可以像操作一个`Buffer`那样方便的对组合`Buffer`进行操作，避免了传统通过内存拷贝的方式将几个小`Buffer`合并成一个大的`Buffer`。

* `Netty`的文件传输采用了`transferTo`方法，它可以直接将文件缓冲区的数据发送到目标`Channel`，避免了传统通过循环`write`方式导致的内存拷贝问题。

### 基于内存池的缓冲区重用机制

随着`JVM`虚拟机和`JIT`即时编译技术的发展，对象的分配和回收是个非常轻量级的工作。

但是对于缓冲区`Buffer`，情况却稍有不同，特别是对于堆外直接内存的分配和回收，是一件耗时的操作。

为了尽量重用缓冲区，`Netty`提供了基于内存池的缓冲区重用机制。


### 灵活的TCP参数配置能力
合理设置`TCP`参数在某些场景下对于性能的提升可以起到显著的效果，例如`SO_RCVBUF`和`SO_SNDBUF`。如果设置不当，对性能的影响是非常大的。下面我们总结下对性能影响比较大的几个配置项：

* `SO_RCVBUF`和`SO_SNDBUF`：通常建议值为`128K`或者`256K`；

* `SO_TCPNODELAY`：`NAGLE`算法通过将缓冲区内的小封包自动相连，组成较大的封包，阻止大量小封包的发送阻塞网络，从而提高网络应用效率。但是对于时延敏感的应用场景需要关闭该优化算法；

* 软中断：如果Linux内核版本支持RPS（2.6.35以上版本），开启RPS后可以实现软中断，提升网络吞吐量。RPS根据数据包的源地址，目的地址以及目的和源端口，计算出一个hash值，然后根据这个hash值来选择软中断运行的cpu，从上层来看，也就是说将每个连接和cpu绑定，并通过这个hash值，来均衡软中断在多个cpu上，提升网络并行处理性能。

`Netty`在启动辅助类中可以灵活的配置`TCP`参数，满足不同的用户场景。